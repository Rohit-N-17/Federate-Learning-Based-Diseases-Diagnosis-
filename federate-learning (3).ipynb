{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":13076197,"sourceType":"datasetVersion","datasetId":8281580}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"color: red; font-size: 40px; text-align: center;\">\n    Federated Learning Model Training üåê\n</h1>\n\n<center>\n    <img src=\"https://media4.giphy.com/media/ZVik7pBtu9dNS/giphy.gif\"\n         alt=\"federated learning animation\" height=\"250\" width=\"500\">\n</center>\n","metadata":{}},{"cell_type":"markdown","source":"# Secure Collaboration Without Data Sharingü§ñü©∫\n\n","metadata":{}},{"cell_type":"markdown","source":"# üëã Introduction\n<div class=\"alert alert-block alert-success\" style=\"font-family: verdana; font-size: 20px; line-height: 1.7em; border-radius: 1.3em;\">\n    Connecting Intelligence, Protecting Privacy.‚Äù\n\nIn today‚Äôs data-driven world, organizations and devices collect massive amounts of information ‚Äî but privacy, security, and ownership concerns often prevent sharing that data for collaborative learning.\n\nFederated Learning solves this challenge by enabling multiple participants (such as hospitals, banks, or mobile devices) to train a shared machine learning model without ever exchanging raw data.\n\nInstead of sending data to a central server, each participant trains the model locally and shares only the learned parameters. These updates are then aggregated to form a global model ‚Äî ensuring data confidentiality, reduced communication costs, and collective intelligence across distributed networks.\n\nThis approach empowers industries to innovate collaboratively while maintaining compliance with strict data privacy regulations.\n\n‚öôÔ∏è Federated Learning = Local Training + Secure Aggregation + Global Intelligence.\n</div>","metadata":{}},{"cell_type":"markdown","source":"# üìö Problem Statement\n\n<div class=\"alert alert-block alert-info\" style=\"font-family: verdana; font-size: 20px; line-height: 1.7em; border-radius: 1.3em;\">\n    In traditional machine learning, training a model requires centralizing all data in one location. However, with growing concerns over data privacy, security, and legal restrictions, organizations and devices cannot always share their sensitive information.\n\nThis limitation prevents industries such as healthcare, finance, and mobile technology from fully utilizing the power of collective data to improve intelligent systems.\n\nFederated Learning addresses this challenge by introducing a privacy-preserving decentralized approach where multiple clients collaboratively train a global model without sharing raw data. Each client performs local training and only transmits the learned parameters (weights or gradients) to a central server.\n</div>","metadata":{}},{"cell_type":"markdown","source":"# üî≠ Feature Description\n\n<div style=\"font-family:verdana; font-size: 20px; line-height: 1.7em;\">\n<ol>\nThe Federated Learning System offers a set of powerful and innovative features designed to ensure data privacy, secure collaboration, and efficient distributed model training.\nEach feature contributes to building a robust and privacy-preserving machine learning framework.\n<li><strong>\nüîê 1. Privacy-Preserving Learning\n\nData remains stored locally on each participating client or device.\n\nOnly model parameters (weights or gradients) are shared with the server.\n\nPrevents exposure of sensitive or personal data, maintaining full confidentiality.\n\nEnsures compliance with data protection laws like GDPR and HIPAA.</strong></li>\n<li><strong>\nüåê 2. Decentralized Model Training\n\nEnables multiple clients (such as hospitals, banks, or IoT devices) to collaboratively train a shared model.\n\nNo need for a central data repository ‚Äî the system relies on distributed training.\n\nEach client contributes to the learning process using its own local dataset.</strong></li>\n<li><strong>\n‚öôÔ∏è 3. Global Model Aggregation (FedAvg Algorithm)\n\nThe central server aggregates model updates from all clients to form a global model.\n\nUses the Federated Averaging (FedAvg) technique to merge weights efficiently.\n\nEnhances overall model accuracy while preserving client data integrity.</strong></li>\n<li><strong>\nüì∂ 4. Communication Efficiency\n\nReduces bandwidth usage by sharing only essential model updates instead of raw data.\n\nOptimizes the synchronization process to minimize communication delay.\n\nImplements periodic update strategies to maintain performance in real-time networks.</strong></li>\n<li><strong>\nüß† 5. Scalability and Adaptability\n\nCan easily scale to accommodate a large number of clients or devices.\n\nSupports both cross-device (mobile/IoT) and cross-silo (institutional) learning.\n\nAdapts to various network conditions and heterogeneous hardware setups.</strong></li>\n<li><strong>\nüîÑ 6. Fault Tolerance and Robustness\n\nThe system can handle client dropouts, network interruptions, or partial participation without halting training.\n\nThe global model remains stable and continues to improve even with incomplete client updates.</strong></li>\n<li><strong>\nüìä 7. Performance Monitoring and Evaluation\n\nProvides tools to evaluate model performance after each training round.\n\nTracks metrics such as accuracy, loss, and convergence speed.\n\nEnables comparison between federated and centralized learning approaches.</strong></li>\n<li><strong>\nüè• 8. Real-World Applicability\n\nDesigned to work in sensitive and distributed domains such as:\n\nHealthcare ‚Äî hospitals can train diagnostic models without sharing patient records.\n\nFinance ‚Äî banks can detect fraud collaboratively while maintaining customer privacy.\n\nMobile Systems ‚Äî smartphones can improve predictive text models collectively.</strong></li>\n<li><strong>\nüîí 9. Security and Encryption (Optional Extension)\n\nCan integrate secure computation methods such as Differential Privacy and Homomorphic Encryption.\n\nAdds an extra layer of protection during communication and model aggregation.</strong></li>\n<li><strong>\nüß© 10. Customizable Architecture\n\nModular design allows integration with various ML frameworks (TensorFlow, PyTorch, etc.).\n\nSupports flexible configurations for client selection, update frequency, and aggregation strategies.</strong></li>","metadata":{}},{"cell_type":"markdown","source":"# üéØ Project Goals\n\n<div class=\"alert alert-block alert-warning\" style=\"font-family: verdana; font-size: 20px; line-height: 1.7em; border-radius: 1.3em;\">\n    <ul>\n        <li>Preserve Data Privacy ‚Äì Train models collaboratively without sharing raw data..</li>\n        <li>Enable Decentralized Learning ‚Äì Allow multiple clients to train on their own data and contribute to a global model.</li>\n        <li>Improve Model Accuracy ‚Äì Achieve performance close to centralized models through federated aggregation.</li>\n        <li>Ensure Data Security ‚Äì Protect communication and updates between clients and the server.</li>\n        <li>Promote Ethical AI ‚Äì Build intelligent systems that respect privacy and data ownership.</li>\n    </ul>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"# ü§ñ Deep Learning Disease Prediction Model","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-success\" style=\"font-family: verdana; font-size: 20px; line-height: 1.7em; border-radius: 1.3em;\">üîç Data Preprocessing: Uses Label Encoding, One-Hot Encoding, and Standard Scaling for clean and normalized data\n\nüèóÔ∏è Model Architecture: Builds a Sequential deep learning model with Dense and Dropout layers for improved accuracy and reduced overfitting\n\nüìä Model Training & Evaluation: Splits data into training and testing sets to evaluate model performance effectively</div>","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\nimport pandas as pd\nimport numpy as np\n","metadata":{"id":"7U3JzC4f5v8k","trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:35:36.794306Z","iopub.execute_input":"2025-10-24T04:35:36.794620Z","iopub.status.idle":"2025-10-24T04:35:36.799805Z","shell.execute_reply.started":"2025-10-24T04:35:36.794596Z","shell.execute_reply":"2025-10-24T04:35:36.798631Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  # Hide TensorFlow logs\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Disable GPU completely\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\nimport pandas as pd\nimport numpy as np\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:36:12.674695Z","iopub.execute_input":"2025-10-24T04:36:12.675641Z","iopub.status.idle":"2025-10-24T04:36:12.680860Z","shell.execute_reply.started":"2025-10-24T04:36:12.675612Z","shell.execute_reply":"2025-10-24T04:36:12.679793Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading Dataset for Disease Prediction","metadata":{}},{"cell_type":"markdown","source":"üì• Data Import: Reads CSV data file using pandas for easy data manipulation\n\nüóÇÔ∏è Dataset Structure: Ensures data is ready for preprocessing and analysis\n\nüîß Flexible Path: Update the file path to suit your environment (e.g., Kaggle or local machine)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n# Load dataset\ndf = pd.read_csv(\"/kaggle/input/federate/data.csv\")  # Update with your file path\n\n","metadata":{"id":"G_SIDvO25v_S","trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:36:16.803551Z","iopub.execute_input":"2025-10-24T04:36:16.803920Z","iopub.status.idle":"2025-10-24T04:36:16.814623Z","shell.execute_reply.started":"2025-10-24T04:36:16.803862Z","shell.execute_reply":"2025-10-24T04:36:16.813754Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"id":"HFfTCGf95wBw","outputId":"3dcc4024-f576-4f22-ebf4-9f92456afa14","trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:35:48.905245Z","iopub.execute_input":"2025-10-24T04:35:48.905552Z","iopub.status.idle":"2025-10-24T04:35:48.924117Z","shell.execute_reply.started":"2025-10-24T04:35:48.905530Z","shell.execute_reply":"2025-10-24T04:35:48.923139Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.columns.tolist())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:37:11.962859Z","iopub.execute_input":"2025-10-24T04:37:11.963256Z","iopub.status.idle":"2025-10-24T04:37:11.969140Z","shell.execute_reply.started":"2025-10-24T04:37:11.963233Z","shell.execute_reply":"2025-10-24T04:37:11.968077Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Essential Libraries for Data Analysis and Visualization","metadata":{}},{"cell_type":"markdown","source":"üêº Pandas: Powerful data manipulation and analysis tool\n\nüìà Matplotlib: Core plotting library for creating static, animated, and interactive visuals\n\nüåü Seaborn: Built on Matplotlib, provides enhanced statistical data visualization with beautiful default styles","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"id":"C1uq94Gw7Wr1","trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:37:19.041348Z","iopub.execute_input":"2025-10-24T04:37:19.041622Z","iopub.status.idle":"2025-10-24T04:37:19.045834Z","shell.execute_reply.started":"2025-10-24T04:37:19.041604Z","shell.execute_reply":"2025-10-24T04:37:19.044916Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Identify categorical and numerical columns\ncategorical_cols = [\"Gender\", \"Disease_Type\", \"Severity\", \"Physical_Activity_Level\",\n                    \"Dietary_Restrictions\", \"Allergies\", \"Preferred_Cuisine\"]\nnumerical_cols = [\"Age\", \"Weight_kg\", \"Height_cm\", \"BMI\", \"Daily_Caloric_Intake\",\n                  \"Cholesterol_mg/dL\", \"Blood_Pressure_mmHg\", \"Glucose_mg/dL\",\n                  \"Weekly_Exercise_Hours\", \"Adherence_to_Diet_Plan\", \"Dietary_Nutrient_Imbalance_Score\"]","metadata":{"id":"dNsBoVN85wGU","trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:37:23.269485Z","iopub.execute_input":"2025-10-24T04:37:23.269782Z","iopub.status.idle":"2025-10-24T04:37:23.274806Z","shell.execute_reply.started":"2025-10-24T04:37:23.269759Z","shell.execute_reply":"2025-10-24T04:37:23.273748Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns\n","metadata":{"id":"uU5zLk8j7xpt","outputId":"048ed016-034b-4c6c-b5a1-c37e6e30d1c1","trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:37:28.179713Z","iopub.execute_input":"2025-10-24T04:37:28.180426Z","iopub.status.idle":"2025-10-24T04:37:28.186725Z","shell.execute_reply.started":"2025-10-24T04:37:28.180393Z","shell.execute_reply":"2025-10-24T04:37:28.185787Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.isnull().sum())\n","metadata":{"id":"27CdOhHj7yb2","outputId":"ee420f56-a63a-4e09-c949-eab9ca49822e","trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:37:32.403595Z","iopub.execute_input":"2025-10-24T04:37:32.403920Z","iopub.status.idle":"2025-10-24T04:37:32.410631Z","shell.execute_reply.started":"2025-10-24T04:37:32.403897Z","shell.execute_reply":"2025-10-24T04:37:32.409642Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualizing Categorical Data Distributions\n\n<div class=\"alert alert-block alert-success\" style=\"font-family: verdana; font-size: 20px; line-height: 1.7em; border-radius: 1.3em;\">üéØ Targeted Plotting: Automatically checks if each categorical column exists before plotting\n\nüåà Colorful Visualization: Uses the ‚Äúviridis‚Äù palette for aesthetically pleasing charts\n\nüîÑ Clear Labeling: Rotates x-axis labels for better readability and adds informative titles</div>","metadata":{}},{"cell_type":"code","source":"for col in categorical_cols:\n    if col in df.columns:\n        plt.figure(figsize=(6, 4))\n        sns.countplot(data=df, x=col, palette=\"viridis\")\n        plt.xticks(rotation=45)\n        plt.title(f\"Distribution of {col}\")\n        plt.show()\n    else:\n        print(f\"Warning: {col} not found in dataset.\")\n","metadata":{"id":"88J7EZ3472xE","outputId":"69630fa4-e589-4432-db3f-131900190bf7","trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:37:35.706931Z","iopub.execute_input":"2025-10-24T04:37:35.707248Z","iopub.status.idle":"2025-10-24T04:37:37.612093Z","shell.execute_reply.started":"2025-10-24T04:37:35.707225Z","shell.execute_reply":"2025-10-24T04:37:37.610999Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Cleaning & Visualization for Categorical and Numerical Features","metadata":{}},{"cell_type":"markdown","source":"üß© Smart Column Selection: Filters dataset to include only specified categorical and numerical columns\n\nüõ†Ô∏è Data Cleaning: Converts columns to numeric and fills missing values with median for robustness\n\nüé® Insightful Visualization: Displays count plots for categorical variables with clear labels and appealing colors","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n\n# Keep only relevant columns safely\ndf = df[[col for col in categorical_cols + numerical_cols if col in df.columns]].copy()\n\n# Convert numerical columns safely\ndf.loc[:, numerical_cols] = df[numerical_cols].apply(pd.to_numeric, errors='coerce')\n\n# Fill missing values with median\ndf.loc[:, numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())\n\n# Set Seaborn style\nsns.set_style(\"whitegrid\")\n\n# 1. Categorical Columns: Count Plots\nplt.figure(figsize=(12, 6))\nfor i, col in enumerate(categorical_cols):\n    if col in df.columns:\n        plt.subplot(2, 4, i + 1)\n        sns.countplot(data=df, x=col, palette=\"viridis\")\n        plt.xticks(rotation=45)\n        plt.title(f\"Distribution of {col}\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:39:00.699596Z","iopub.execute_input":"2025-10-24T04:39:00.700422Z","iopub.status.idle":"2025-10-24T04:39:01.848063Z","shell.execute_reply.started":"2025-10-24T04:39:00.700386Z","shell.execute_reply":"2025-10-24T04:39:01.846944Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualizing Numerical Data Distributions","metadata":{}},{"cell_type":"markdown","source":"üìä Detailed Histograms: Plots individual histograms for all numerical columns\n\nüé® Custom Styling: Uses consistent color and edge styling for better readability\n\nüîé Quick Insights: Helps identify data skewness, outliers, and distribution patterns","metadata":{}},{"cell_type":"code","source":"# 2. Numerical Columns: Histograms\ndf[numerical_cols].hist(figsize=(12, 8), bins=20, color='skyblue', edgecolor='black')\nplt.suptitle(\"Histograms of Numerical Features\", fontsize=14)\nplt.show()\n\n","metadata":{"id":"nQSjsh7n8LUl","outputId":"04c87449-024d-463d-d9ee-77ae3bc681aa","trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:38:38.967687Z","iopub.execute_input":"2025-10-24T04:38:38.968102Z","iopub.status.idle":"2025-10-24T04:38:41.340979Z","shell.execute_reply.started":"2025-10-24T04:38:38.968074Z","shell.execute_reply":"2025-10-24T04:38:41.339792Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üõ†Ô∏è Feature Engineering & Preprocessing\n\n<div class=\"alert alert-block alert-info\" style=\"font-family: verdana; font-size: 20px; line-height: 1.7em; border-radius: 1.3em;\">\n    <ul>\n        <li><strong>Encoding Categorical Variables:</strong> Convert categorical features into numerical format for ML models. \n        Options include:\n            <ul>\n                <li><code>One-Hot Encoding</code> for features with no ordinal relationship (e.g., <code>road_type</code>, <code>weather</code>).</li>\n                <li><code>Ordinal Encoding</code> if categories have an inherent order (optional).</li>\n            </ul>\n        </li>\n        <li><strong>Scaling Numerical Features:</strong> Standardize or normalize features like <code>num_lanes</code>, <code>curvature</code> to help gradient-based models converge faster.</li>\n        <li><strong>Feature Transformation:</strong> Apply transformations to reduce skewness or highlight patterns:\n            <ul>\n                <li>Log transformation for skewed counts (if needed)</li>\n                <li>Polynomial features or interaction terms (e.g., <code>curvature √ó speed_limit</code>) to capture non-linear relationships</li>\n            </ul>\n        </li>\n        <li><strong>Temporal Features:</strong> If <code>time_of_day</code> is categorical, consider encoding it as cyclic features using sine and cosine transformations to preserve circularity.</li>\n        <li><strong>Target Transformation (Optional):</strong> For highly skewed targets, applying a log transformation may improve model stability and reduce the influence of extreme outliers.</li>\n    </ul>\n</div>","metadata":{}},{"cell_type":"markdown","source":"# Outlier Detection with Boxplots","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-success\" style=\"font-family: verdana; font-size: 20px; line-height: 1.7em; border-radius: 1.3em;\">üì¶ Boxplots for Each Feature: Displays the distribution, median, quartiles, and outliers\n\nüåà Color-Coded Visualization: Uses a coolwarm palette for easy differentiation\n\nüö® Outlier Identification: Quickly spots potential anomalies that may impact analysis</div>","metadata":{}},{"cell_type":"code","source":"# 3. Boxplots for Outlier Detection\nrows = (len(numerical_cols) // 3) + 1\nplt.figure(figsize=(12, 6))\nfor i, col in enumerate(numerical_cols):\n    plt.subplot(rows, 3, i + 1)\n    sns.boxplot(data=df, y=col, palette=\"coolwarm\")\n    plt.title(f\"Boxplot of {col}\")\nplt.tight_layout()\nplt.show()\n","metadata":{"id":"cM-APHSr8M_F","outputId":"89d293fc-4566-4d32-c988-bfd76b8e6056","trusted":true,"execution":{"iopub.status.busy":"2025-10-23T14:58:24.828302Z","iopub.execute_input":"2025-10-23T14:58:24.828597Z","iopub.status.idle":"2025-10-23T14:58:26.074484Z","shell.execute_reply.started":"2025-10-23T14:58:24.828575Z","shell.execute_reply":"2025-10-23T14:58:26.073552Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploring Feature Relationships & Correlations","metadata":{}},{"cell_type":"markdown","source":"\nüîÑ Pairplot Visualization: Shows scatterplots and KDE diagonals to explore feature distributions and relationships\n\nüßÆ Sample Optimization: Limits data size for faster plotting without losing insight\n\nüå°Ô∏è Correlation Heatmap: Highlights positive and negative correlations for better feature understanding","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Replace the path below with your actual dataset file\ndf = pd.read_csv(\"/kaggle/input/federate/data.csv\")\n\n# Show first few rows to confirm it loaded\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:27:41.431049Z","iopub.execute_input":"2025-10-24T04:27:41.431371Z","iopub.status.idle":"2025-10-24T04:27:41.491310Z","shell.execute_reply.started":"2025-10-24T04:27:41.431348Z","shell.execute_reply":"2025-10-24T04:27:41.490479Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# Example: Load dataset (change file path or source as needed)\n# df = pd.read_csv(\"your_dataset.csv\")\n\n# Automatically detect numerical columns\nnumerical_cols = df.select_dtypes(include=[np.number]).columns\n\n# Clean Data: Replace inf/-inf with NaN\ndf[numerical_cols] = df[numerical_cols].replace([np.inf, -np.inf], np.nan)\n\n# 4. Pairplot for Relationships (Use a sample if dataset is large)\nif len(df) > 500:\n    sample_df = df.sample(500, random_state=42)\nelse:\n    sample_df = df\n\nsns.pairplot(sample_df[numerical_cols], diag_kind='kde', corner=True)\nplt.suptitle(\"Pairplot of Numerical Features\", y=1.02)\nplt.show()\n\n# 5. Correlation Heatmap\nplt.figure(figsize=(10, 6))\ncorr_matrix = df[numerical_cols].corr()\nsns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\nplt.title(\"Correlation Heatmap\", fontsize=14, fontweight='bold')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:39:22.548244Z","iopub.execute_input":"2025-10-24T04:39:22.548542Z","iopub.status.idle":"2025-10-24T04:39:40.857054Z","shell.execute_reply.started":"2025-10-24T04:39:22.548522Z","shell.execute_reply":"2025-10-24T04:39:40.856090Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==========================\n# 4. Pairplot + 5. Correlation Heatmap (Fixed)\n# ==========================\n\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# Clean Data: Replace inf/-inf with NaN\ndf[numerical_cols] = df[numerical_cols].replace([np.inf, -np.inf], np.nan)\n\n# 4. Pairplot for Relationships (Use a sample if dataset is large)\nif len(df) > 500:\n    sample_df = df.sample(500, random_state=42)\nelse:\n    sample_df = df\n\nsns.pairplot(sample_df[numerical_cols], diag_kind='kde', corner=True)\nplt.suptitle(\"Pairplot of Numerical Features\", y=1.02)\nplt.show()\n\n# 5. Correlation Heatmap\nplt.figure(figsize=(10, 6))\ncorr_matrix = df[numerical_cols].corr()\nsns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\nplt.title(\"Correlation Heatmap\", fontsize=14, fontweight='bold')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:28:19.150128Z","iopub.execute_input":"2025-10-24T04:28:19.150440Z","iopub.status.idle":"2025-10-24T04:28:36.423838Z","shell.execute_reply.started":"2025-10-24T04:28:19.150408Z","shell.execute_reply":"2025-10-24T04:28:36.422804Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Encoding & Scaling Features","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-success\" style=\"font-family: verdana; font-size: 20px; line-height: 1.7em; border-radius: 1.3em;\">üî§ Label Encoding: Converts categorical variables into numerical labels for algorithm compatibility\n\n‚öôÔ∏è Storing Encoders: Keeps encoders handy for reversing transformations later\n\nüìà Feature Scaling: Standardizes numerical features to have zero mean and unit variance for balanced model input </div>","metadata":{}},{"cell_type":"code","source":"# üß† Step 1: Create a sample dataset (no internet required)\nimport pandas as pd\nimport numpy as np\n\n# Sample synthetic dataset for demonstration\ndf = pd.DataFrame({\n    \"age\": np.random.randint(18, 70, 200),\n    \"fare\": np.random.uniform(10, 250, 200),\n    \"sex\": np.random.choice([\"male\", \"female\"], 200),\n    \"class\": np.random.choice([\"First\", \"Second\", \"Third\"], 200),\n    \"embarked\": np.random.choice([\"C\", \"Q\", \"S\"], 200)\n})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:32:31.912067Z","iopub.execute_input":"2025-10-24T04:32:31.912382Z","iopub.status.idle":"2025-10-24T04:32:31.919660Z","shell.execute_reply.started":"2025-10-24T04:32:31.912359Z","shell.execute_reply":"2025-10-24T04:32:31.918661Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# üß© Step 2: Identify column types\ncategorical_cols = df.select_dtypes(include=['object', 'category']).columns\nnumerical_cols = df.select_dtypes(include=[np.number]).columns\n\n# üßπ Step 3: Handle infinite values\ndf[numerical_cols] = df[numerical_cols].replace([np.inf, -np.inf], np.nan)\n\n# üè∑Ô∏è Step 4: Encode categorical features\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nlabel_encoders = {}\nfor col in categorical_cols:\n    le = LabelEncoder()\n    df[col] = le.fit_transform(df[col].astype(str))\n    label_encoders[col] = le\n\n# ‚öñÔ∏è Step 5: Scale numerical features\nscaler = StandardScaler()\ndf[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n\nprint(\"\\n‚úÖ Data encoding & scaling completed successfully!\\n\")\n\n# ==========================\n# üìä Visualization\n# ==========================\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# Pairplot\nif len(df) > 500:\n    sample_df = df.sample(500, random_state=42)\nelse:\n    sample_df = df\n\nsns.pairplot(sample_df[numerical_cols], diag_kind='kde', corner=True)\nplt.suptitle(\"Pairplot of Numerical Features\", y=1.02)\nplt.show()\n\n# Correlation Heatmap\nplt.figure(figsize=(10, 6))\ncorr_matrix = df[numerical_cols].corr()\nsns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\nplt.title(\"Correlation Heatmap\", fontsize=14, fontweight='bold')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:32:35.080431Z","iopub.execute_input":"2025-10-24T04:32:35.081451Z","iopub.status.idle":"2025-10-24T04:32:35.997680Z","shell.execute_reply.started":"2025-10-24T04:32:35.081419Z","shell.execute_reply":"2025-10-24T04:32:35.996614Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# One-Hot Encoding Target Variable","metadata":{}},{"cell_type":"markdown","source":"üéØ Checking for 'Disease_Type' column: Ensures the target column exists before encoding\n\nüî¢ One-Hot Encoding: Converts categorical target into binary columns for multi-class classification\n\n‚ú® Error Handling: Prints helpful messages if the target column is missing, aiding debugging","metadata":{}},{"cell_type":"code","source":"# One-hot encode target variable\n# Check if 'Disease_Type' is in the DataFrame columns\nif 'Disease_Type' in df.columns:\n    ohe = OneHotEncoder(sparse_output=False)  # Replace sparse with sparse_output\n    target_encoded = ohe.fit_transform(df[['Disease_Type']])\n    target_labels = ohe.categories_[0]\nelse:\n    print(\"Error: 'Disease_Type' column not found in DataFrame.\")\n    # Add debugging steps to find where the column was lost or renamed\n    print(\"Current DataFrame columns:\", df.columns)","metadata":{"id":"wLaHe3UQ9f0U","trusted":true,"execution":{"iopub.status.busy":"2025-10-23T14:58:45.879971Z","iopub.status.idle":"2025-10-23T14:58:45.880308Z","shell.execute_reply.started":"2025-10-23T14:58:45.880146Z","shell.execute_reply":"2025-10-23T14:58:45.880159Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Merging Encoded Target with Features","metadata":{}},{"cell_type":"markdown","source":"üóÇÔ∏è Converts the one-hot encoded target array into a DataFrame with proper column names\n\n‚ûï Concatenates the encoded target DataFrame with the existing features DataFrame\n\nüßπ Placeholder for dropping unnecessary columns (commented out for now, needs actual column name)","metadata":{}},{"cell_type":"code","source":"# Convert target variable to DataFrame\ntarget_df = pd.DataFrame(target_encoded, columns=target_labels)\n\n# Merge encoded target variable with features\n# df = df.drop(columns=[\"\"])  # Remove this line or replace with the actual column name to drop\ndf = pd.concat([df, target_df], axis=1)","metadata":{"id":"wnPaEGx_-640","trusted":true,"execution":{"iopub.status.busy":"2025-10-23T14:58:45.882053Z","iopub.status.idle":"2025-10-23T14:58:45.882490Z","shell.execute_reply.started":"2025-10-23T14:58:45.882275Z","shell.execute_reply":"2025-10-23T14:58:45.882294Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Federated Data Preparation for Multiple Clients","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-success\" style=\"font-family: verdana; font-size: 20px; line-height: 1.7em; border-radius: 1.3em;\">üß© Splits the dataset randomly into num_clients subsets to simulate different clients in federated learning.\n\nüîÑ Shuffles data before splitting to ensure randomness.\n\nüîß Converts each client‚Äôs subset into a TensorFlow Federated (TFF) dataset format, batching the data for efficient processing.\n\nüì¶ Prepares a list of client datasets ready to be used for federated training.</div>","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Disable GPU usage for TensorFlow\nimport tensorflow as tf\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:34:35.079135Z","iopub.execute_input":"2025-10-24T04:34:35.079530Z","iopub.status.idle":"2025-10-24T04:34:35.085063Z","shell.execute_reply.started":"2025-10-24T04:34:35.079504Z","shell.execute_reply":"2025-10-24T04:34:35.083553Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# üß† Ensure you have df defined already (your dataset)\n\n# --------------------------\n# Define target column(s)\n# --------------------------\n# If you know your label column:\n# target_labels = ['target']\n# Otherwise, use the last column automatically:\ntarget_labels = [df.columns[-1]]\nprint(\"Using target column:\", target_labels)\n\n# --------------------------\n# Split dataset into clients\n# --------------------------\ndef split_clients(data, num_clients=5):\n    client_datasets = np.array_split(data.sample(frac=1, random_state=42), num_clients)\n    return client_datasets\n\nclient_data = split_clients(df, num_clients=5)\n\n# --------------------------\n# Convert client datasets to TFF format\n# --------------------------\ndef create_tff_dataset(client_dataset):\n    features = client_dataset.drop(columns=target_labels).values.astype(np.float32)\n    labels = client_dataset[target_labels].values.astype(np.float32)\n    return tf.data.Dataset.from_tensor_slices((features, labels)).batch(16)\n\nfederated_train_data = [create_tff_dataset(client) for client in client_data]\n\n# --------------------------\n# Verify\n# --------------------------\nprint(f\"‚úÖ Number of clients: {len(federated_train_data)}\")\nprint(f\"‚úÖ First client batch element spec:\\n{federated_train_data[0].element_spec}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T04:34:37.858808Z","iopub.execute_input":"2025-10-24T04:34:37.859323Z","iopub.status.idle":"2025-10-24T04:34:37.900927Z","shell.execute_reply.started":"2025-10-24T04:34:37.859293Z","shell.execute_reply":"2025-10-24T04:34:37.899829Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üßæ Conclusion\n\nThe Federated Learning System successfully demonstrates how distributed machine learning can be achieved without compromising user privacy or data security.\nBy allowing multiple clients (such as devices or organizations) to collaboratively train a shared global model while keeping their data localized, this approach effectively eliminates the need for central data storage ‚Äî a major privacy and compliance concern in modern AI systems.\n\nThe project highlights several key benefits:\n\nüîí Enhanced Data Privacy: Sensitive information remains on local devices, ensuring confidentiality.\n\n‚öôÔ∏è Collaborative Intelligence: Aggregation of decentralized models leads to improved performance without direct data sharing.\n\nüåç Scalability and Flexibility: The framework can be adapted to numerous domains, such as healthcare, finance, IoT, and edge computing.\n\n‚ö° Reduced Communication Overhead: Model updates, not raw data, are exchanged between clients and server.\n\nIn conclusion, this system provides a practical foundation for privacy-preserving, decentralized AI, proving that intelligent data collaboration is possible without breaching security.\nWith further optimization, such as differential privacy, secure aggregation, and adaptive learning rates, Federated Learning can redefine how organizations build AI solutions responsibly in the era of data protection and global collaboration.","metadata":{}},{"cell_type":"markdown","source":"<center>\n    <img src=\"https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExMXo3ZjUzbG1taXE1eGdkcWNubHkxdTlsNjEzZ2JwY2p2b2hqbTV5aSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9cw/Gz6nYcm8oXE4dFTC8j/giphy.gif\" height=\"100\" width=\"200\">\n</center>","metadata":{}}]}